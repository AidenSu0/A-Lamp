{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Patch_Selection_Prod_Ray.ipynb","provenance":[],"collapsed_sections":["rQRotPCMQdt_","yxVgNhkWzuQS","xIMsqapq_OyA","BPU5sgcveHz_","s3qjfmJS97M5","CC9wfU6nOzrt","7CSi5IUdO36b"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"K3cXIadzygfM","colab_type":"text"},"source":["<h1><center>Adaptative Patch Selection - Ray<center></h1>\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XT-ZMt5HRxrj","colab_type":"text"},"source":["Simon Albergel, PRIM 2020, Meero"]},{"cell_type":"markdown","metadata":{"id":"rQRotPCMQdt_","colab_type":"text"},"source":["##Setup"]},{"cell_type":"markdown","metadata":{"id":"62d9qKhfQjDW","colab_type":"text"},"source":["Import packages & setup drive"]},{"cell_type":"code","metadata":{"id":"V8pgbMbS9DPo","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import itertools\n","import pickle\n","import tarfile\n","import pdb\n","import glob\n","import time\n","from scipy.optimize import minimize\n","from scipy.linalg import fractional_matrix_power, inv\n","from cv2 import cvtColor, GaussianBlur, Sobel, CV_64F, COLOR_BGR2HSV, COLOR_BGR2GRAY"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9kKSflhHSPw5","colab_type":"code","outputId":"0c6468b3-0720-473b-ae85-c1395ad6f5ab","executionInfo":{"status":"ok","timestamp":1582549249687,"user_tz":-60,"elapsed":2358,"user":{"displayName":"Simon Albergel","photoUrl":"","userId":"04489016538160601488"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["help(os)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["absl-py==0.9.0\n","alabaster==0.7.12\n","albumentations==0.1.12\n","altair==4.0.1\n","asgiref==3.2.3\n","astor==0.8.1\n","astropy==4.0\n","atari-py==0.2.6\n","atomicwrites==1.3.0\n","attrs==19.3.0\n","audioread==2.1.8\n","autograd==1.3\n","Babel==2.8.0\n","backcall==0.1.0\n","backports.tempfile==1.0\n","backports.weakref==1.0.post1\n","beautifulsoup4==4.6.3\n","bleach==3.1.0\n","blis==0.2.4\n","bokeh==1.4.0\n","boto==2.49.0\n","boto3==1.11.15\n","botocore==1.14.15\n","Bottleneck==1.3.1\n","branca==0.3.1\n","bs4==0.0.1\n","bz2file==0.98\n","cachetools==3.1.1\n","certifi==2019.11.28\n","cffi==1.14.0\n","chainer==6.5.0\n","chardet==3.0.4\n","chart-studio==1.0.0\n","Click==7.0\n","cloudpickle==1.2.2\n","cmake==3.12.0\n","colorlover==0.3.0\n","community==1.0.0b1\n","contextlib2==0.5.5\n","convertdate==2.2.0\n","coverage==3.7.1\n","coveralls==0.5\n","crcmod==1.7\n","cufflinks==0.17.0\n","cupy-cuda101==6.5.0\n","cvxopt==1.2.4\n","cvxpy==1.0.25\n","cycler==0.10.0\n","cymem==2.0.3\n","Cython==0.29.15\n","daft==0.0.4\n","dask==2.9.2\n","dataclasses==0.7\n","datascience==0.10.6\n","decorator==4.4.1\n","defusedxml==0.6.0\n","descartes==1.1.0\n","dill==0.3.1.1\n","distributed==1.25.3\n","Django==3.0.3\n","dlib==19.18.0\n","dm-sonnet==1.35\n","docopt==0.6.2\n","docutils==0.15.2\n","dopamine-rl==1.0.5\n","earthengine-api==0.1.213\n","easydict==1.9\n","ecos==2.0.7.post1\n","editdistance==0.5.3\n","en-core-web-sm==2.1.0\n","entrypoints==0.3\n","et-xmlfile==1.0.1\n","fa2==0.3.5\n","fancyimpute==0.4.3\n","fastai==1.0.60\n","fastdtw==0.3.4\n","fastprogress==0.2.2\n","fastrlock==0.4\n","fbprophet==0.5\n","feather-format==0.4.0\n","featuretools==0.4.1\n","filelock==3.0.12\n","fix-yahoo-finance==0.0.22\n","Flask==1.1.1\n","folium==0.8.3\n","fsspec==0.6.2\n","future==0.16.0\n","gast==0.2.2\n","GDAL==2.2.2\n","gdown==3.6.4\n","gensim==3.6.0\n","geographiclib==1.50\n","geopy==1.17.0\n","gevent==1.4.0\n","gin-config==0.3.0\n","glob2==0.7\n","google==2.0.3\n","google-api-core==1.16.0\n","google-api-python-client==1.7.11\n","google-auth==1.7.2\n","google-auth-httplib2==0.0.3\n","google-auth-oauthlib==0.4.1\n","google-cloud-bigquery==1.21.0\n","google-cloud-core==1.0.3\n","google-cloud-datastore==1.8.0\n","google-cloud-language==1.2.0\n","google-cloud-storage==1.16.2\n","google-cloud-translate==1.5.0\n","google-colab==1.0.0\n","google-pasta==0.1.8\n","google-resumable-media==0.4.1\n","googleapis-common-protos==1.51.0\n","googledrivedownloader==0.4\n","graph-nets==1.0.5\n","graphviz==0.10.1\n","greenlet==0.4.15\n","grpcio==1.27.1\n","gspread==3.0.1\n","gspread-dataframe==3.0.4\n","gunicorn==20.0.4\n","gym==0.15.6\n","h5py==2.8.0\n","HeapDict==1.0.1\n","holidays==0.9.12\n","html5lib==1.0.1\n","httpimport==0.5.18\n","httplib2==0.11.3\n","httplib2shim==0.0.3\n","humanize==0.5.1\n","hyperopt==0.1.2\n","ideep4py==2.0.0.post3\n","idna==2.8\n","image==1.5.28\n","imageio==2.4.1\n","imagesize==1.2.0\n","imbalanced-learn==0.4.3\n","imblearn==0.0\n","imgaug==0.2.9\n","importlib-metadata==1.5.0\n","imutils==0.5.3\n","inflect==2.1.0\n","intel-openmp==2020.0.133\n","intervaltree==2.1.0\n","ipykernel==4.6.1\n","ipython==5.5.0\n","ipython-genutils==0.2.0\n","ipython-sql==0.3.9\n","ipywidgets==7.5.1\n","itsdangerous==1.1.0\n","jax==0.1.58\n","jaxlib==0.1.38\n","jdcal==1.4.1\n","jedi==0.16.0\n","jieba==0.42.1\n","Jinja2==2.11.1\n","jmespath==0.9.4\n","joblib==0.14.1\n","jpeg4py==0.1.4\n","jsonschema==2.6.0\n","jupyter==1.0.0\n","jupyter-client==5.3.4\n","jupyter-console==5.2.0\n","jupyter-core==4.6.2\n","kaggle==1.5.6\n","kapre==0.1.3.1\n","Keras==2.2.5\n","Keras-Applications==1.0.8\n","Keras-Preprocessing==1.1.0\n","keras-vis==0.4.1\n","kfac==0.2.0\n","kiwisolver==1.1.0\n","knnimpute==0.1.0\n","librosa==0.6.3\n","lightgbm==2.2.3\n","llvmlite==0.31.0\n","lmdb==0.98\n","lucid==0.3.8\n","lunardate==0.2.0\n","lxml==4.2.6\n","magenta==0.3.19\n","Markdown==3.2.1\n","MarkupSafe==1.1.1\n","matplotlib==3.1.3\n","matplotlib-venn==0.11.5\n","mesh-tensorflow==0.1.9\n","mido==1.2.6\n","mir-eval==0.5\n","missingno==0.4.2\n","mistune==0.8.4\n","mizani==0.6.0\n","mkl==2019.0\n","mlxtend==0.14.0\n","more-itertools==8.2.0\n","moviepy==0.2.3.5\n","mpi4py==3.0.3\n","mpmath==1.1.0\n","msgpack==0.5.6\n","multiprocess==0.70.9\n","multitasking==0.0.9\n","murmurhash==1.0.2\n","music21==5.5.0\n","natsort==5.5.0\n","nbconvert==5.6.1\n","nbformat==5.0.4\n","networkx==2.4\n","nibabel==2.3.3\n","nltk==3.2.5\n","notebook==5.2.2\n","np-utils==0.5.12.1\n","numba==0.47.0\n","numexpr==2.7.1\n","numpy==1.17.5\n","nvidia-ml-py3==7.352.0\n","oauth2client==4.1.3\n","oauthlib==3.1.0\n","okgrade==0.4.3\n","opencv-contrib-python==4.1.2.30\n","opencv-python==4.1.2.30\n","openpyxl==2.5.9\n","opt-einsum==3.1.0\n","osqp==0.6.1\n","packaging==20.1\n","palettable==3.3.0\n","pandas==0.25.3\n","pandas-datareader==0.7.4\n","pandas-gbq==0.11.0\n","pandas-profiling==1.4.1\n","pandocfilters==1.4.2\n","parso==0.6.1\n","pathlib==1.0.1\n","patsy==0.5.1\n","pexpect==4.8.0\n","pickleshare==0.7.5\n","Pillow==6.2.2\n","pip-tools==4.2.0\n","plac==0.9.6\n","plotly==4.4.1\n","plotnine==0.6.0\n","pluggy==0.7.1\n","portpicker==1.3.1\n","prefetch-generator==1.0.1\n","preshed==2.0.1\n","pretty-midi==0.2.8\n","prettytable==0.7.2\n","progressbar2==3.38.0\n","prometheus-client==0.7.1\n","promise==2.3\n","prompt-toolkit==1.0.18\n","protobuf==3.10.0\n","psutil==5.4.8\n","psycopg2==2.7.6.1\n","ptyprocess==0.6.0\n","py==1.8.1\n","pyarrow==0.14.1\n","pyasn1==0.4.8\n","pyasn1-modules==0.2.8\n","pycocotools==2.0.0\n","pycparser==2.19\n","pydata-google-auth==0.3.0\n","pydot==1.3.0\n","pydot-ng==2.0.0\n","pydotplus==2.0.2\n","PyDrive==1.3.1\n","pyemd==0.5.1\n","pyglet==1.4.10\n","Pygments==2.1.3\n","pygobject==3.26.1\n","pymc3==3.7\n","PyMeeus==0.3.6\n","pymongo==3.10.1\n","pymystem3==0.2.0\n","PyOpenGL==3.1.5\n","pyparsing==2.4.6\n","pypng==0.0.20\n","pyrsistent==0.15.7\n","pysndfile==1.3.8\n","PySocks==1.7.1\n","pystan==2.19.1.1\n","pytest==3.6.4\n","python-apt==1.6.5+ubuntu0.2\n","python-chess==0.23.11\n","python-dateutil==2.6.1\n","python-louvain==0.13\n","python-rtmidi==1.4.0\n","python-slugify==4.0.0\n","python-utils==2.3.0\n","pytz==2018.9\n","PyWavelets==1.1.1\n","PyYAML==3.13\n","pyzmq==17.0.0\n","qtconsole==4.6.0\n","regex==2019.12.20\n","requests==2.21.0\n","requests-oauthlib==1.3.0\n","resampy==0.2.2\n","retrying==1.3.3\n","rpy2==2.9.5\n","rsa==4.0\n","s3fs==0.4.0\n","s3transfer==0.3.3\n","scikit-image==0.16.2\n","scikit-learn==0.22.1\n","scipy==1.4.1\n","screen-resolution-extra==0.0.0\n","scs==2.1.1.post2\n","seaborn==0.10.0\n","semantic-version==2.8.4\n","Send2Trash==1.5.0\n","setuptools-git==1.2\n","Shapely==1.7.0\n","simplegeneric==0.8.1\n","six==1.12.0\n","sklearn==0.0\n","sklearn-pandas==1.8.0\n","smart-open==1.9.0\n","snowballstemmer==2.0.0\n","sortedcontainers==2.1.0\n","spacy==2.1.9\n","Sphinx==1.8.5\n","sphinxcontrib-websupport==1.2.0\n","SQLAlchemy==1.3.13\n","sqlparse==0.3.0\n","srsly==1.0.1\n","stable-baselines==2.2.1\n","statsmodels==0.10.2\n","sympy==1.1.1\n","tables==3.4.4\n","tabulate==0.8.6\n","tblib==1.6.0\n","tensor2tensor==1.14.1\n","tensorboard==1.15.0\n","tensorboardcolab==0.0.22\n","tensorflow==1.15.0\n","tensorflow-datasets==2.0.0\n","tensorflow-estimator==1.15.1\n","tensorflow-gan==2.0.0\n","tensorflow-hub==0.7.0\n","tensorflow-metadata==0.21.1\n","tensorflow-privacy==0.2.2\n","tensorflow-probability==0.7.0\n","termcolor==1.1.0\n","terminado==0.8.3\n","testpath==0.4.4\n","text-unidecode==1.3\n","textblob==0.15.3\n","textgenrnn==1.4.1\n","tflearn==0.3.2\n","Theano==1.0.4\n","thinc==7.0.8\n","toolz==0.10.0\n","torch==1.4.0\n","torchsummary==1.5.1\n","torchtext==0.3.1\n","torchvision==0.5.0\n","tornado==4.5.3\n","tqdm==4.28.1\n","traitlets==4.3.3\n","tweepy==3.6.0\n","typing==3.6.6\n","typing-extensions==3.6.6\n","tzlocal==1.5.1\n","umap-learn==0.3.10\n","uritemplate==3.0.1\n","urllib3==1.24.3\n","vega-datasets==0.8.0\n","wasabi==0.6.0\n","wcwidth==0.1.8\n","webencodings==0.5.1\n","Werkzeug==1.0.0\n","widgetsnbextension==3.5.1\n","wordcloud==1.5.0\n","wrapt==1.11.2\n","xarray==0.14.1\n","xgboost==0.90\n","xkit==0.0.0\n","xlrd==1.1.0\n","xlwt==1.3.0\n","yellowbrick==0.9.1\n","zict==1.0.0\n","zipp==3.0.0\n","zmq==0.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lmKmo1wLizC9","colab_type":"code","outputId":"9ba83b87-1494-4d57-c2fa-fa7f158f2e70","executionInfo":{"status":"error","timestamp":1582549226304,"user_tz":-60,"elapsed":1359,"user":{"displayName":"Simon Albergel","photoUrl":"","userId":"04489016538160601488"}},"colab":{"base_uri":"https://localhost:8080/","height":316}},"source":["import psutil\n","import ray "],"execution_count":0,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-747a55165900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"GerS33fOQp2c","colab_type":"text"},"source":["Define Paths"]},{"cell_type":"code","metadata":{"id":"uM5KzVouAxyS","colab_type":"code","colab":{}},"source":["workpath = 'drive/My Drive/Colab Notebooks/Meero'\n","\n","datapath = os.path.join(workpath, 'AVA_dataset')\n","outputpath = os.path.join(workpath, 'output_files')\n","modelpath = os.path.join(datapath, 'objectness_trained_model')\n","testpath = os.path.join(workpath,'images_test')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lO6UmnEEQF80","colab_type":"code","colab":{}},"source":["# load the input image for testing purposes\n","imagename = os.path.join('girl.jpg')\n","image = cv2.imread(imagename)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s3qjfmJS97M5","colab_type":"text"},"source":["###Saliency Detection via Graph-Based Manifold Ranking"]},{"cell_type":"markdown","metadata":{"id":"dDq71BHS-SCk","colab_type":"text"},"source":["Based on : C. Yang, L. Zhang, H. Lu, X. Ruan, and M. H. Yang.\n","Saliency detection via graph-based manifold ranking. In\n","Computer Vision and Pattern Recognition (CVPR), 2013\n","IEEE Conference on, pages 3166–3173, June 2013."]},{"cell_type":"markdown","metadata":{"id":"P_Pu2s6S-EbA","colab_type":"text"},"source":["#####Import Python implementation of the paper"]},{"cell_type":"code","metadata":{"id":"P1n44-ercUqr","colab_type":"code","outputId":"3288e15c-48e9-453d-e70d-9e1d49e2102b","executionInfo":{"status":"ok","timestamp":1581532434265,"user_tz":-60,"elapsed":592,"user":{"displayName":"Simon Albergel","photoUrl":"","userId":"04489016538160601488"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["####################################################################\n","## Author:\n","##       Xiang Ruan\n","##       httpr://ruanxiang.net\n","##       ruanxiang@gmail.com\n","## License:\n","##       GPL 2.0\n","##       NOTE: the algorithm itself is patented by OMRON, co, Japan\n","##             my previous employer, so please do not use the algorithm in\n","##             any commerical product\n","## Version:\n","##       1.01\n","##\n","## ----------------------------------------------------------------\n","## A python implementation of manifold ranking saliency\n","## Usage:\n","##      import MR\n","##      import matplotlib.pyplot as plt\n","##      mr = MR.MR_saliency()\n","##      sal = mr.saliency(img)\n","##      plt.imshow(sal)\n","##      plt.show()\n","##\n","## Check paper.pdf for algorithm details \n","## I leave all th parameters open to maniplating, however, you don't\n","## have to do it, default values work pretty well, unless you really\n","## know what you want to do to modify the parameters\n","\n","\n","import scipy as sp\n","from skimage.segmentation import slic\n","from skimage.segmentation import mark_boundaries\n","from skimage.data import camera\n","from scipy.linalg import pinv\n","\n","cv_ver = int(cv2.__version__.split('.')[0])\n","_cv2_LOAD_IMAGE_COLOR = cv2.IMREAD_COLOR if cv_ver >= 3 else cv2.CV_LOAD_IMAGE_COLOR\n","\n","class MR_saliency(object):\n","    \"\"\"Python implementation of manifold ranking saliency\"\"\"\n","    weight_parameters = {'alpha':0.99,\n","                         'delta':0.1}\n","    superpixel_parameters = {'segs':200,\n","                             'compactness':10,\n","                             'max_iter':10,\n","                             'sigma':1,\n","                             'spacing':None,\n","                             'multichannel':True,\n","                             'convert2lab':None,\n","                             'enforce_connectivity':False,\n","                             'min_size_factor':0.5,\n","                             'max_size_factor':3,\n","                             'slic_zero':False}\n","    binary_thre = None\n","\n","    def __init__(self, alpha = 0.99, delta = 0.1,\n","                 segs = 200, compactness = 10,\n","                 max_iter = 10, sigma = 1,\n","                 spacing = None, multichannel = True,\n","                 convert2lab = None, enforce_connectivity = False,\n","                 min_size_factor = 0.5, max_size_factor = 3,\n","                 slic_zero = False):\n","        self.weight_parameters['alpha'] = alpha\n","        self.weight_parameters['delta'] = delta\n","        self.superpixel_parameters['segs'] = segs\n","        self.superpixel_parameters['compactness'] = compactness\n","        self.superpixel_parameters['max_iter'] = max_iter\n","        self.superpixel_parameters['sigma'] = sigma\n","        self.superpixel_parameters['spacing'] = spacing\n","        self.superpixel_parameters['multichannel'] = multichannel\n","        self.superpixel_parameters['convert2lab'] = convert2lab\n","        self.superpixel_parameters['enforce_connectivity'] = enforce_connectivity\n","        self.superpixel_parameters['min_size_factor'] = min_size_factor\n","        self.superpixel_parameters['max_size_factor'] = max_size_factor\n","        self.superpixel_parameters['slic_zero'] = slic_zero\n","\n","    def saliency(self,img):\n","        # read image\n","        img = self.__MR_readimg(img)\n","        # superpixel\n","        labels = self.__MR_superpixel(img)\n","        # affinity matrix\n","        aff = self.__MR_affinity_matrix(img,labels)\n","        # first round\n","        first_sal = self.__MR_first_stage_saliency(aff,labels)\n","        # second round\n","        fin_sal = self.__MR_final_saliency(first_sal,labels,aff)\n","        return self.__MR_fill_superpixel_with_saliency(labels,fin_sal)\n","\n","    \n","    def __MR_superpixel(self,img):\n","        return slic(img,self.superpixel_parameters['segs'],\n","                    self.superpixel_parameters['compactness'],\n","                    self.superpixel_parameters['max_iter'],\n","                    self.superpixel_parameters['sigma'],\n","                    self.superpixel_parameters['spacing'],\n","                    self.superpixel_parameters['multichannel'],\n","                    self.superpixel_parameters['convert2lab'],\n","                    self.superpixel_parameters['enforce_connectivity'],\n","                    self.superpixel_parameters['min_size_factor'],\n","                    self.superpixel_parameters['max_size_factor'],\n","                    self.superpixel_parameters['slic_zero'])\n","\n","    def __MR_superpixel_mean_vector(self,img,labels):\n","        s = sp.amax(labels)+1\n","        vec = sp.zeros((s,3)).astype(float)\n","        for i in range(s):\n","            mask = labels == i\n","            super_v = img[mask].astype(float)\n","            mean = sp.mean(super_v,0)\n","            vec[i] = mean\n","        return vec\n","\n","    def __MR_affinity_matrix(self,img,labels):        \n","        W,D = self.__MR_W_D_matrix(img,labels)\n","        aff = pinv(D-self.weight_parameters['alpha']*W)\n","        aff[sp.eye(sp.amax(labels)+1).astype(bool)] = 0.0 # diagonal elements to 0\n","        return aff\n","\n","    def __MR_saliency(self,aff,indictor):\n","        return sp.dot(aff,indictor)\n","\n","    def __MR_W_D_matrix(self,img,labels):\n","        s = sp.amax(labels)+1\n","        vect = self.__MR_superpixel_mean_vector(img,labels)\n","        \n","        adj = self.__MR_get_adj_loop(labels)\n","        \n","        W = sp.spatial.distance.squareform(sp.spatial.distance.pdist(vect))\n","        \n","        W = sp.exp(-1*W / self.weight_parameters['delta'])\n","        W[adj.astype(np.bool)] = 0\n","        \n","\n","        D = sp.zeros((s,s)).astype(float)\n","        for i in range(s):\n","            D[i, i] = sp.sum(W[i])\n","\n","        return W,D\n","\n","    def __MR_boundary_indictor(self,labels):\n","        s = sp.amax(labels)+1\n","        up_indictor = (sp.ones((s,1))).astype(float)\n","        right_indictor = (sp.ones((s,1))).astype(float)\n","        low_indictor = (sp.ones((s,1))).astype(float)\n","        left_indictor = (sp.ones((s,1))).astype(float)\n","    \n","        upper_ids = sp.unique(labels[0,:]).astype(int)\n","        right_ids = sp.unique(labels[:,labels.shape[1]-1]).astype(int)\n","        low_ids = sp.unique(labels[labels.shape[0]-1,:]).astype(int)\n","        left_ids = sp.unique(labels[:,0]).astype(int)\n","\n","        up_indictor[upper_ids] = 0.0\n","        right_indictor[right_ids] = 0.0\n","        low_indictor[low_ids] = 0.0\n","        left_indictor[left_ids] = 0.0\n","\n","        return up_indictor,right_indictor,low_indictor,left_indictor\n","\n","    def __MR_second_stage_indictor(self,saliency_img_mask,labels):\n","        s = sp.amax(labels)+1\n","        # get ids from labels image\n","        ids = sp.unique(labels[saliency_img_mask]).astype(int)\n","        # indictor\n","        indictor = sp.zeros((s,1)).astype(float)\n","        indictor[ids] = 1.0\n","        return indictor\n","\n","    def __MR_get_adj_loop(self, labels):\n","        s = sp.amax(labels) + 1\n","        adj = np.ones((s, s), np.bool)\n","\n","        for i in range(labels.shape[0] - 1):\n","            for j in range(labels.shape[1] - 1):\n","                if labels[i, j] != labels[i+1, j]:\n","                    adj[labels[i, j],       labels[i+1, j]]              = False\n","                    adj[labels[i+1, j],   labels[i, j]]                  = False\n","                if labels[i, j] != labels[i, j + 1]:\n","                    adj[labels[i, j],       labels[i, j+1]]              = False\n","                    adj[labels[i, j+1],   labels[i, j]]                  = False\n","                if labels[i, j] != labels[i + 1, j + 1]:\n","                    adj[labels[i, j]        ,  labels[i+1, j+1]]       = False\n","                    adj[labels[i+1, j+1],  labels[i, j]]               = False\n","                if labels[i + 1, j] != labels[i, j + 1]:\n","                    adj[labels[i+1, j],   labels[i, j+1]]              = False\n","                    adj[labels[i, j+1],   labels[i+1, j]]              = False\n","        \n","        upper_ids = sp.unique(labels[0,:]).astype(int)\n","        right_ids = sp.unique(labels[:,labels.shape[1]-1]).astype(int)\n","        low_ids = sp.unique(labels[labels.shape[0]-1,:]).astype(int)\n","        left_ids = sp.unique(labels[:,0]).astype(int)\n","        \n","        bd = np.append(upper_ids, right_ids)\n","        bd = np.append(bd, low_ids)\n","        bd = sp.unique(np.append(bd, left_ids))\n","        \n","        for i in range(len(bd)):\n","            for j in range(i + 1, len(bd)):\n","                adj[bd[i], bd[j]] = False\n","                adj[bd[j], bd[i]] = False\n","\n","        return adj\n","        \n","    def __MR_fill_superpixel_with_saliency(self,labels,saliency_score):\n","        sa_img = labels.copy().astype(float)\n","        for i in range(sp.amax(labels)+1):\n","            mask = labels == i\n","            sa_img[mask] = saliency_score[i]\n","        return cv2.normalize(sa_img,None,0,255,cv2.NORM_MINMAX)\n","\n","    def __MR_first_stage_saliency(self,aff,labels):\n","        up,right,low,left = self.__MR_boundary_indictor(labels)\n","        up_sal = 1- self.__MR_saliency(aff,up)\n","        up_img = self.__MR_fill_superpixel_with_saliency(labels,up_sal)\n","    \n","        right_sal = 1-self.__MR_saliency(aff,right)\n","        right_img = self.__MR_fill_superpixel_with_saliency(labels,right_sal)\n","\n","        low_sal = 1-self.__MR_saliency(aff,low)\n","        low_img = self.__MR_fill_superpixel_with_saliency(labels,low_sal)\n","    \n","        left_sal = 1-self.__MR_saliency(aff,left)\n","        left_img = self.__MR_fill_superpixel_with_saliency(labels,left_sal)\n","\n","        return 1- up_img*right_img*low_img*left_img\n","\n","\n","    def __MR_final_saliency(self,integrated_sal, labels, aff):\n","        # get binary image\n","        if self.binary_thre == None:\n","            thre = sp.median(integrated_sal.astype(float))\n","\n","        mask = integrated_sal > thre\n","        # get indicator\n","        ind = self.__MR_second_stage_indictor(mask,labels)\n","    \n","        return self.__MR_saliency(aff,ind)\n","\n","    # read image\n","    def __MR_readimg(self,img):\n","        if isinstance(img,str): # a image path\n","            img = cv2.imread(img, _cv2_LOAD_IMAGE_COLOR)\n","        img = cv2.cvtColor(img,cv2.COLOR_RGB2LAB).astype(float)/255\n","        # Keeping the image in full size\n","        #h = 100\n","        #w = int(float(h)/float(img.shape[0])*float(img.shape[1]))\n","        #return cv2.resize(img,(w,h))\n","        return img\n","\n","\"\"\"\n","class MR_debuger(MR_saliency):\n","    def MR_showsuperpixel(self,img=None):\n","        if img == None:\n","            img = cv2.cvtColor(camera(),cv2.COLOR_RGB2BGR)\n","        img = self._MR_saliency__MR_readimg(img)\n","        labels = self._MR_saliency__MR_superpixel(img)\n","\n","        plt.axis('off')\n","        plt.imshow(mark_boundaries(img,labels))\n","        plt.show()\n","\n","    def MR_boudnary_extraction(self,img=None):\n","        if img == None:\n","            img = cv2.cvtColor(camera(),cv2.COLOR_RGB2BGR)\n","        lab_img = self._MR_saliency__MR_readimg(img)\n","        mark_color = (1,0,0)\n","        labels = self._MR_saliency__MR_superpixel(lab_img)\n","\n","        up_img = lab_img.copy()\n","        up_ids = sp.unique(labels[0,:]).astype(int)\n","        up_mask = sp.zeros(labels.shape).astype(bool)\n","        for i in up_ids:\n","            up_mask = sp.logical_or(up_mask,labels==i)\n","        up_img[up_mask] = mark_color\n","        up_img = mark_boundaries(up_img,labels)\n","\n","        right_img = lab_img.copy()\n","        right_ids = sp.unique(labels[:,labels.shape[1]-1]).astype(int)\n","        right_mask = sp.zeros(labels.shape).astype(bool)\n","        for i in right_ids:\n","            right_mask = sp.logical_or(right_mask,labels==i)\n","        right_img[right_mask] = mark_color\n","        right_img = mark_boundaries(right_img,labels)\n","\n","\n","        low_img = lab_img.copy()\n","        low_ids = sp.unique(labels[labels.shape[0]-1,:]).astype(int)\n","        low_mask = sp.zeros(labels.shape).astype(bool)\n","        for i in low_ids:\n","            low_mask = sp.logical_or(low_mask,labels==i)\n","        low_img[low_mask] = mark_color\n","        low_img = mark_boundaries(low_img,labels)\n","        \n","        left_img = lab_img.copy()\n","        left_ids = sp.unique(labels[:,0]).astype(int)\n","        left_mask = sp.zeros(labels.shape).astype(bool)\n","        for i in left_ids:\n","            left_mask = sp.logical_or(left_mask,labels==i)\n","        left_img[left_mask] = mark_color\n","        left_img = mark_boundaries(left_img,labels)\n","\n","        plt.subplot(2,2,1)\n","        plt.axis('off')\n","        plt.title('up')\n","        plt.imshow(up_img)\n","\n","        plt.subplot(2,2,2)\n","        plt.axis('off')\n","        plt.title('bottom')\n","        plt.imshow(low_img)\n","\n","\n","        plt.subplot(2,2,3)\n","        plt.axis('off')\n","        plt.title('left')\n","        plt.imshow(left_img)\n","\n","        plt.subplot(2,2,4)\n","        plt.axis('off')\n","        plt.title('right')\n","        plt.imshow(right_img)\n","\n","        plt.show()\n","\n","\n","    def MR_boundary_saliency(self,img=None):\n","        if img == None:\n","            img = cv2.cvtColor(camera(),cv2.COLOR_RGB2BGR)\n","        lab_img = self._MR_saliency__MR_readimg(img)\n","    \n","        labels = self._MR_saliency__MR_superpixel(lab_img)\n","        \n","        up,right,low,left = self._MR_saliency__MR_boundary_indictor(labels)\n","        aff = self._MR_saliency__MR_affinity_matrix(lab_img,labels)\n","\n","        up_sal = 1- self._MR_saliency__MR_saliency(aff,up)\n","        up_img = self._MR_saliency__MR_fill_superpixel_with_saliency(labels,up_sal)\n","        up_img = up_img.astype(np.uint8)\n","    \n","        right_sal = 1-self._MR_saliency__MR_saliency(aff,right)\n","        right_img =  self._MR_saliency__MR_fill_superpixel_with_saliency(labels,right_sal)\n","        right_img = right_img.astype(np.uint8)\n","\n","        low_sal = 1-self._MR_saliency__MR_saliency(aff,low)\n","        low_img = self._MR_saliency__MR_fill_superpixel_with_saliency(labels,low_sal)\n","        low_img = low_img.astype(np.uint8)\n","    \n","        left_sal = 1-self._MR_saliency__MR_saliency(aff,left)\n","        left_img = self._MR_saliency__MR_fill_superpixel_with_saliency(labels,left_sal)\n","        left_img = left_img.astype(np.uint8)\n","        \n","\n","        plt.subplot(3,2,1)\n","        plt.title('orginal')\n","        plt.axis('off')\n","        plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n","        \n","        plt.subplot(3,2,2)\n","        plt.title('up')\n","        plt.axis('off')\n","        plt.imshow(up_img,'gray')\n","        \n","        plt.subplot(3,2,3)\n","        plt.title('right')\n","        plt.axis('off')\n","        plt.imshow(right_img,'gray')\n","        \n","        plt.subplot(3,2,4)\n","        plt.title('low')\n","        plt.axis('off')\n","        plt.imshow(low_img,'gray')\n","        \n","        plt.subplot(3,2,5)\n","        plt.title('left')\n","        plt.axis('off')\n","        plt.imshow(left_img,'gray')\n","        \n","        plt.subplot(3,2,6)\n","        plt.title('integrated')\n","        plt.axis('off')\n","        saliency_map = MR_debuger().saliency(img).astype(np.uint8)\n","        plt.imshow( saliency_map,'gray')\n","        plt.show()\n","\"\"\""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nclass MR_debuger(MR_saliency):\\n    def MR_showsuperpixel(self,img=None):\\n        if img == None:\\n            img = cv2.cvtColor(camera(),cv2.COLOR_RGB2BGR)\\n        img = self._MR_saliency__MR_readimg(img)\\n        labels = self._MR_saliency__MR_superpixel(img)\\n\\n        plt.axis('off')\\n        plt.imshow(mark_boundaries(img,labels))\\n        plt.show()\\n\\n    def MR_boudnary_extraction(self,img=None):\\n        if img == None:\\n            img = cv2.cvtColor(camera(),cv2.COLOR_RGB2BGR)\\n        lab_img = self._MR_saliency__MR_readimg(img)\\n        mark_color = (1,0,0)\\n        labels = self._MR_saliency__MR_superpixel(lab_img)\\n\\n        up_img = lab_img.copy()\\n        up_ids = sp.unique(labels[0,:]).astype(int)\\n        up_mask = sp.zeros(labels.shape).astype(bool)\\n        for i in up_ids:\\n            up_mask = sp.logical_or(up_mask,labels==i)\\n        up_img[up_mask] = mark_color\\n        up_img = mark_boundaries(up_img,labels)\\n\\n        right_img = lab_img.copy()\\n        right_ids = sp.unique(labels[:,labels.shape[1]-1]).astype(int)\\n        right_mask = sp.zeros(labels.shape).astype(bool)\\n        for i in right_ids:\\n            right_mask = sp.logical_or(right_mask,labels==i)\\n        right_img[right_mask] = mark_color\\n        right_img = mark_boundaries(right_img,labels)\\n\\n\\n        low_img = lab_img.copy()\\n        low_ids = sp.unique(labels[labels.shape[0]-1,:]).astype(int)\\n        low_mask = sp.zeros(labels.shape).astype(bool)\\n        for i in low_ids:\\n            low_mask = sp.logical_or(low_mask,labels==i)\\n        low_img[low_mask] = mark_color\\n        low_img = mark_boundaries(low_img,labels)\\n        \\n        left_img = lab_img.copy()\\n        left_ids = sp.unique(labels[:,0]).astype(int)\\n        left_mask = sp.zeros(labels.shape).astype(bool)\\n        for i in left_ids:\\n            left_mask = sp.logical_or(left_mask,labels==i)\\n        left_img[left_mask] = mark_color\\n        left_img = mark_boundaries(left_img,labels)\\n\\n        plt.subplot(2,2,1)\\n        plt.axis('off')\\n        plt.title('up')\\n        plt.imshow(up_img)\\n\\n        plt.subplot(2,2,2)\\n        plt.axis('off')\\n        plt.title('bottom')\\n        plt.imshow(low_img)\\n\\n\\n        plt.subplot(2,2,3)\\n        plt.axis('off')\\n        plt.title('left')\\n        plt.imshow(left_img)\\n\\n        plt.subplot(2,2,4)\\n        plt.axis('off')\\n        plt.title('right')\\n        plt.imshow(right_img)\\n\\n        plt.show()\\n\\n\\n    def MR_boundary_saliency(self,img=None):\\n        if img == None:\\n            img = cv2.cvtColor(camera(),cv2.COLOR_RGB2BGR)\\n        lab_img = self._MR_saliency__MR_readimg(img)\\n    \\n        labels = self._MR_saliency__MR_superpixel(lab_img)\\n        \\n        up,right,low,left = self._MR_saliency__MR_boundary_indictor(labels)\\n        aff = self._MR_saliency__MR_affinity_matrix(lab_img,labels)\\n\\n        up_sal = 1- self._MR_saliency__MR_saliency(aff,up)\\n        up_img = self._MR_saliency__MR_fill_superpixel_with_saliency(labels,up_sal)\\n        up_img = up_img.astype(np.uint8)\\n    \\n        right_sal = 1-self._MR_saliency__MR_saliency(aff,right)\\n        right_img =  self._MR_saliency__MR_fill_superpixel_with_saliency(labels,right_sal)\\n        right_img = right_img.astype(np.uint8)\\n\\n        low_sal = 1-self._MR_saliency__MR_saliency(aff,low)\\n        low_img = self._MR_saliency__MR_fill_superpixel_with_saliency(labels,low_sal)\\n        low_img = low_img.astype(np.uint8)\\n    \\n        left_sal = 1-self._MR_saliency__MR_saliency(aff,left)\\n        left_img = self._MR_saliency__MR_fill_superpixel_with_saliency(labels,left_sal)\\n        left_img = left_img.astype(np.uint8)\\n        \\n\\n        plt.subplot(3,2,1)\\n        plt.title('orginal')\\n        plt.axis('off')\\n        plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\\n        \\n        plt.subplot(3,2,2)\\n        plt.title('up')\\n        plt.axis('off')\\n        plt.imshow(up_img,'gray')\\n        \\n        plt.subplot(3,2,3)\\n        plt.title('right')\\n        plt.axis('off')\\n        plt.imshow(right_img,'gray')\\n        \\n        plt.subplot(3,2,4)\\n        plt.title('low')\\n        plt.axis('off')\\n        plt.imshow(low_img,'gray')\\n        \\n        plt.subplot(3,2,5)\\n        plt.title('left')\\n        plt.axis('off')\\n        plt.imshow(left_img,'gray')\\n        \\n        plt.subplot(3,2,6)\\n        plt.title('integrated')\\n        plt.axis('off')\\n        saliency_map = MR_debuger().saliency(img).astype(np.uint8)\\n        plt.imshow( saliency_map,'gray')\\n        plt.show()\\n\""]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"7BIUNKkekOxu","colab_type":"text"},"source":["##Utils"]},{"cell_type":"code","metadata":{"id":"iJ67G7E1pe-m","colab_type":"code","colab":{}},"source":["#Filter out scipy's deprecation error\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EFD224PAQ66Q","colab_type":"code","colab":{}},"source":["#Get the number of PHYSICAL cores\n","num_cpus = psutil.cpu_count(logical=False)\n","\n","#Init ray with the adequate number of cores (don't forget to shutdown any previous instance)\n","ray.shutdown()\n","ray.init(num_cpus=num_cpus)\n","\n","@ray.remote  \n","class SelectAdaptativePatch(object):\n","  def __init__(self, filename, image, S, patch_size=[112, 112]):\n","    self.filename = filename\n","    self.image = image\n","    self.patch_size = patch_size\n","    self.S = S\n","\n","    self.E_x, self.E_y, self.H = self.preComputeF()\n","\n","  def preComputeF(self):\n","\n","    ## E_x, E_y edge maps (on x & y)\n","    gray = cvtColor(self.image, COLOR_BGR2GRAY)\n","    gray_clean = GaussianBlur(gray,(3,3),0)\n","    E_x = np.asarray(Sobel(gray_clean, CV_64F,1,0,ksize=5))\n","    E_y = np.asarray(Sobel(gray_clean, CV_64F,0,1,ksize=5))\n","\n","    ## H chrominancy map ; we chose to use hue to score \"colorfullness\"\n","    #Hue formula from BGR following Frank Preucil, 1953\n","    H = np.arctan2(np.sqrt(3) * (self.image[:, :, 1] - self.image[:, :, 0]), 2 * self.image[:, :, 2] - self.image[:, :, 1] - self.image[:, :, 0])\n","\n","    #pdb.set_trace()\n","\n","    return E_x, E_y, H\n","\n","  def wassertsteinDistance(self, sigma_i, sigma_j):\n","    # Following F. Pitie and A. Kokaram\n","    for i in range(sigma_i.shape[0]):\n","      if sigma_i[i][i] == 0: \n","        sigma_i[i][i] += 0.1\n","      if sigma_j[i][i] == 0: \n","        sigma_j[i][i] += 0.1\n","\n","    sigma_i_sqrt = fractional_matrix_power(sigma_i, .5)\n","    sigma_i_sqrt_inv = np.linalg.inv(sigma_i_sqrt)\n","    sigma_intermediate = np.dot(sigma_i_sqrt, sigma_j)\n","    sigma_temp = fractional_matrix_power(np.nan_to_num(np.dot(sigma_intermediate, sigma_i_sqrt)), .5)\n","\n","    #pdb.set_trace()\n","\n","    return np.dot(np.dot(sigma_i_sqrt_inv, sigma_temp), sigma_i_sqrt_inv)\n","\n","  def D_p(self, E_x_i, E_x_j, E_y_i, E_y_j, H_i, H_j):\n","    # Pattern Diversity\n","    ## Edge \n","    sigma_e_x_i = np.var(E_x_i)\n","    sigma_e_x_j = np.var(E_x_i)\n","\n","    sigma_e_y_i = np.var(E_y_i)\n","    sigma_e_y_j = np.var(E_y_i)\n","\n","    ## Chrominance (Hue)\n","    sigma_h_i = np.var(H_i)\n","    sigma_h_j = np.var(H_j)\n","\n","    # Earth's Mover Distance \n","    sigma_i = np.diag([sigma_e_x_i, sigma_e_y_i, sigma_h_i])\n","    sigma_j = np.diag([sigma_e_x_j, sigma_e_y_j, sigma_h_j])\n","\n","    emd = self.wassertsteinDistance(sigma_i, sigma_j)\n","    \n","    return np.trace(emd).mean()\n","\n","  def initialize_five_centers_line(self):\n","    shape = self.image.shape[1], self.image.shape[0]\n","    safety = 1 \n","\n","    if shape[1] > shape[0]:\n","      y0 = shape[1] // 2\n","      x_step = (shape[0] - 2*self.patch_size[0]) // 5\n","                                                                                \n","      x = [self.patch_size[0] + safety, y0,\n","            self.patch_size[0] + x_step, y0,\n","            self.patch_size[0] + 2*x_step, y0,\n","            self.patch_size[0] + 3*x_step, y0,\n","            self.patch_size[0] + 4*x_step - safety, y0]    \n","\n","    else:\n","      x0 = shape[0] // 2\n","      y_step = (shape[1] - 2*self.patch_size[1]) // 5\n","                                                                                \n","      x = [x0, self.patch_size[1] + safety,\n","          x0, self.patch_size[1] + y_step, \n","          x0, self.patch_size[1] + 2*y_step, \n","          x0, self.patch_size[1] + 3*y_step, \n","          x0, self.patch_size[1] + 4*y_step - safety] \n","                  \n","    return np.array(x)\n","\n","  def computeF(self, centers):\n","    #<0 : to minimize\n","    centers = centers.reshape(-1, 2).astype(int)\n","\n","    #Init F\n","    F = 0\n","\n","    ## To sum saliency, important : highly dependent on the combination method, here fitted for itertools.combinations\n","    first_loop = True\n","    number_loop = 0\n","\n","    # Compute patches\n","    for center in itertools.combinations(centers, 2):\n","      #Careful : cv2 is switching axis so we have to switch centers coordinates accordingly\n","\n","      #print(number_loop)\n","      E_x_i = self.E_x[(center[0][1] - self.patch_size[0]):(center[0][1] + self.patch_size[0] + 1), (center[0][0] - self.patch_size[1]):(center[0][0] + self.patch_size[1] + 1)]\n","\n","      #2 * radius + 1 (center pixel)\n","      if (E_x_i.size == 0) or (E_x_i.shape[0] != self.patch_size[0] * 2 + 1) or (E_x_i.shape[1] != self.patch_size[1] * 2 + 1):\n","        #print(\"The patch i is stepping outside of the image.\")\n","        return 1\n","\n","      E_x_j = self.E_x[(center[1][1] - self.patch_size[0]):(center[1][1] + self.patch_size[0] + 1), (center[1][0] - self.patch_size[1]):(center[1][0] + self.patch_size[1] + 1)]\n","\n","      if (E_x_j.size == 0) or (E_x_j.shape[0] != self.patch_size[0] * 2 + 1) or (E_x_j.shape[1] != self.patch_size[1] * 2 + 1):\n","        # Given that all of the maps are of the same dimension, only E_x on i and j is enough\n","        #print(\"The patch j is stepping outside of the image.\")\n","        return 1\n","\n","      E_y_i = self.E_y[(center[0][1] - self.patch_size[0]):(center[0][1] + self.patch_size[0] + 1), (center[0][0] - self.patch_size[1]):(center[0][0] + self.patch_size[1] + 1)]\n","      E_y_j = self.E_x[(center[1][1] - self.patch_size[0]):(center[1][1] + self.patch_size[0] + 1), (center[1][0] - self.patch_size[1]):(center[1][0] + self.patch_size[1] + 1)]\n","\n","      H_i = self.H[(center[0][1] - self.patch_size[0]):(center[0][1] + self.patch_size[0] + 1), (center[0][0] - self.patch_size[1]):(center[0][0] + self.patch_size[1] + 1)]\n","      H_j = self.H[(center[1][1] - self.patch_size[0]):(center[1][1] + self.patch_size[0] + 1), (center[1][0] - self.patch_size[1]):(center[1][0] + self.patch_size[1] + 1)]\n","\n","      # Summing saliency\n","      if first_loop:\n","        F += self.S[(center[0][0] - self.patch_size[0]):(center[0][0] + self.patch_size[0] + 1), (center[0][1] - self.patch_size[1]):(center[0][1] + self.patch_size[1] + 1)].mean()\n","        first_loop = False\n","      if number_loop < centers.shape[0] - 1:\n","        F += self.S[(center[1][0] - self.patch_size[0]):(center[1][0] + self.patch_size[0] + 1), (center[1][1] - self.patch_size[1]):(center[1][1] + self.patch_size[1] + 1)].mean()\n","        number_loop += 1\n","\n","      # Pattern diversity (emd)\n","      F = F + self.D_p(E_x_i, E_x_j, E_y_i, E_y_j, H_i, H_j)\n","      \n","      # Euclidean distance between centers\n","      F = F + np.linalg.norm(center[0] - center[1]) / 2 \n","\n","    return - F\n","\n","  def predict(self):\n","    #check if image needs padding (if smaller than self.patch_size)\n","    if self.image.shape[0] < self.patch_size[0]:\n","      pad = (self.patch_size[0] - self.image.shape[0]) // 2 + 1 \n","      self.image = cv2.copyMakeBorder(self.image, pad, pad, 0, 0)\n","\n","    if self.image.shape[0] < self.patch_size[0]:\n","      pad = (self.patch_size[0] - image.shape[0]) // 2 + 1 \n","      self.image = cv2.copyMakeBorder(image, 0, 0, pad, pad)\n","\n","    #Setup\n","    x0 = self.initialize_five_centers_line()\n","\n","    res = minimize(lambda x : self.computeF(x), \\\n","                        x0, \\\n","                        method='Nelder-Mead', \\\n","                        options={'xatol': 10, 'maxiter': 200})\n","    \n","    centers = res.x.reshape(-1, 2).astype(int)\n","    bboxes = np.concatenate((centers[:, [0]] - self.patch_size[0], centers[:, [1]] - self.patch_size[1], centers[:, [0]] + self.patch_size[0], centers[:, [1]] + self.patch_size[1]), axis=1)\n","\n","    return bboxes\n","\n","\n","def main(argv):\n","    \"\"\"\n","        2 argumnents : input_dir, output_dir\n","    \"\"\"\n","        \n","    #get inputs\n","    input_dir = argv[0]\n","    output_dir = argv[1]\n","    \n","    #get all file names\n","    filenames = glob.glob(input_dir + '/*')\n","    \n","    #Init list savers \n","    filenames_temp = []\n","    bboxes_temp = []\n","    \n","    #Init MR_saliency\n","    mr = MR_saliency()\n","    \n","    i = 0\n","    \n","    for filename in filenames:\n","      #First image is no 1\n","      i+=1\n","      \n","      #load image\n","      image = cv2.imread(filename)\n","      \n","      #Compute saliency\n","      S = mr.saliency(image)\n","    \n","      patch_size = [112, 112]\n","    \n","      #check if image needs padding (if smaller than patch_size)\n","      if image.shape[0] < patch_size[0]:\n","        pad = (patch_size[0] - image.shape[0]) // 2 + 1 \n","        image = cv2.copyMakeBorder(image, 0, 0, pad, pad, cv2.BORDER_REFLECT)\n","    \n","      if image.shape[1] < patch_size[1]:\n","        pad = (patch_size[1] - image.shape[1]) // 2 + 1 \n","        image = cv2.copyMakeBorder(image, pad, pad, 0, 0, cv2.BORDER_REFLECT)\n","    \n","      #Run selection of patches\n","      #init\n","      patch_selection = SelectAdaptativePatch(filename, image, S)\n","      #predict\n","      bboxes = patch_selection.predict()\n","    \n","      #save result\n","      filenames_temp.append(filename)\n","      bboxes_temp.append(bboxes)\n","    \n","      #save in pickle periodically\n","      if (i % 1000 == 0):\n","        df = pd.DataFrame({'Filename':filenames_temp, 'BBoxes': bboxes_temp})\n","        filenames_temp = []\n","        bboxes_temp = []\n","    \n","        pickle_out = open(os.path.join(output_dir, str(i) + '_bboxes.pickle'), 'wb')\n","        pickle.dump(df, pickle_out)\n","        pickle_out.close()\n","        \n","    \n","    \n","    df = pd.DataFrame({'Filename':filenames_temp, 'BBoxes': bboxes_temp})\n","    pickle_out = open(os.path.join(output_dir, str(i) + '_bboxes.pickle'), 'wb')\n","    pickle.dump(df, pickle_out)\n","    pickle_out.close()\n","    \n","\n","if __name__ == \"__main__\":\n","   main(sys.argv[1:])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aHF_G93qftbp","colab_type":"text"},"source":["##Tryout"]},{"cell_type":"code","metadata":{"id":"KUZkxWnxci_u","colab_type":"code","colab":{}},"source":["start = time.time()\n","\n","#Tryout using the same image (easier to check if all bboxes are the same i.e. there was not conflicts between running instances)\n","imagenames = [imagename] * num_cpus\n","mr = MR_saliency()\n","images = [cv2.imread(imagename) for imagename in imagenames]\n","\n","#putting images in Ray's shared memory\n","images_id = [ray.put(image) for image in images]\n","S_ids = [ray.put(mr.saliency(image)) for image in images]\n","\n","#Run the script\n","#Init every instance of \n","imgs = [SelectAdaptativePatch.remote(imagename, images_id[i], S_ids[i]) for (i, imagename) in enumerate(imagenames)]\n","bboxes = ray.get([img.predict.remote() for img in imgs])\n","\n","print('RUNTIME : ' + str(time.time() - start))"],"execution_count":0,"outputs":[]}]}